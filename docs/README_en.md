
[**【debate相关论文】**](https://www.cnblogs.com/ExMan/p/18727514)

# 架构优化
策略分为3步：
-   **第1步**：根据问题生成解决方案（zhu）
完成功能：
    1）判断是要 discussion，还是直接回答（例如问候类型问题）；
    2）如果是discussion类问题，则分析用户提出的问题是否准确，是否需要用户提供补充信息，并整理成最新问题。

-   第二步就是多轮相互 discussion（辩论的回合数越多，消耗的token越多，越费时间和money）

-   第三步在discussion的基础上进行投票表决。


---

现有的debate（一种Agentic Workflow）策略分为3步：
-   第一步就是对给定的问题生成解决方案
-   第二步就是多轮相互discussion（辩论的回合数越多，消耗的token越多，越费时间和money）
-   第三步在discussion的基础上进行投票表决。

本质上，agent debate能力涉及到了LLM本身的角色扮演（角色扮演能够提升debate的效果），多轮对话，长序列指令遵循等能力，如果模型把这些能力训练好，debate能力就具备了前置条件了（至少两个智能体的多轮对话debate能够做了）。

现有的debate研究都是一些策略，除了能够消除推理的幻觉（hallucinations），做事实性校验（fact checking）外，还能构建多个LLM的agent通过debate 策略提升数据生成的质量，优化SFT（例如Debatetune，DebateGPT），另外，有人研究了debate策略的拓扑结构，通过简单的debate拓扑结构能够减少token消耗，提升模型的精度（Group Debate），还有人研究了debate后达成一致的投票过程加了置信度（weighted），使用不同的LLM（ChatGPT, Bard, Claude2等）作为agents，典型的有RECONCILE，DebUnc；

还有人研究了在discussion出现平局的情况下引入了一个秘书（secretary）来做最终的结论，典型的是（CMD）；

此外，有研究在disscussion阶段注入RAG知识来打破认知孤岛（cognitive islands，挺有意思的概念），典型的就是MADKE，最后，有人就是直接在训练里面加入debate策略（Acc-Debate），都是一些不错的探索。其实，有人在看debate初始化的时候，需要使用LLM做多次reasoning，感觉就是self-consistency+投票表决，其实只是初始化差不多，MAD还有多轮的迭代对话等等，但是两个策略关系很密切。

**与单智能体相比，MAD在推理上有下面这几个优势：**

- 1.多样化的视角：多智能体辩论允许模型通过与提供意见的其他智能体互动来考虑不同的观点；

- 2.增强推理：通过辩论的互动，模型有机会挑战假设，建立更强有力的论据来提升推理过程；

- 3.错误更正：可以通过辩论框架内的相互讨论来识别和纠正各个智能体之间的不一致的结论和错误；

- 4.性能提升：与单智能体方法相比，MAD利用的是群体智慧，通常会提升模型的整体性能。

也有人会问，single agent会很差吗？这个不一定，single agent有strong prompt的时候能够达到和multi agent相同的效果(CMD论文的观点)，在没有few shot情况下，multi agent的效果是比single agent好很多的。

<p align="center">
<img src="imgs/debate流程.jpg" width="450" />
</p>

[**改进多Agent辩论的稀疏通信拓扑**](https://arxiv.org/abs/2406.11776)

多智能体辩论已被证明能有效提高大型语言模型在推理和事实性任务中的质量。虽然人们已经探索了多智能体辩论中的各种角色扮演策略，但就智能体之间的通信而言，现有方法采用强力算法——每个智能体都可以与所有其他智能体通信。本文系统地研究了通信连接在多智能体系统中的影响。 GPT 和 Mistral 模型上的实验表明，利用稀疏通信拓扑的多智能体辩论可以实现相当或更优异的性能，同时显着降低计算成本。此外，论文将多智能体辩论框架扩展到多模态推理和对齐标记任务，展示了其广泛的适用性和有效性。研究结果强调了通信连接对于提高“society of minds”方法的效率和有效性的重要性。

首先介绍一下MAD，MAD 利用多个LLM agents相互进行讨论，结合他们的推理和批判性思维能力来产生高质量的结果。具体来说，给定一个问题，每个agent首先生成自己的解决方案，然后参考其他agent的解决方案来更新自己的答案。这个过程可以重复几轮。MAD 在事实性和推理任务上表现出显著的进步。虽然辩论过程非常高效，但也非常昂贵：随着 LLM agents的数量和辩论轮次的增加，输入上下文显著扩大。

总结一下，典型的MAD框架包括三个步骤：

-   Individual response generation: 在第 1 轮中，agents使用 LLM 进行初始化，然后独立生成给定问题的解决方案。通常采用随机解码策略来使agent生成的解决方案多样化。
-   Multi agent debate: 从第 2 轮开始，每个agent都会整合上一轮中与其相连的同伴的响应，以批评或改进自己的响应。利用标准的同步对话通信策略来促进异步计算。这个辩论过程可以分多轮进行。
-   Reasoning Consensus: 经过辩论过程后，agent可能仍然有不同的解决方案。在这种情况下，所有agents之间将进行多数投票来确定一致的解决方案。
MAD 可以成为一种有前途的人工智能反馈强化学习 (RLAIF) 和从弱到强的泛化的方法。通过提供更好的奖励信号，MAD 有可能显著帮助对齐大型语言模型。为了评估这一点，首先将 MAD 框架扩展到对齐labeling任务，证明了它与单agent设置相比的有效性。此外，实验验证了在推理任务中观察到的稀疏性优势也适用于对齐labeling任务。

当agents由 MAD 框架内的不同 LLM 实例化时，多个 LLM 之间的交互会导致较弱的模型通过与较强的模型交互而逐渐增强。在非规则图设置中，将较强的 LLM 分配给具有更高中心性的agent始终可以获得更好的性能。论文的贡献如下：

(1) 证明稀疏通信拓扑增强了多智能体辩论框架的有效性和效率；
(2) 评估了稀疏 MAD 在纯文本和多模态推理任务中的表现，表明它优于标准 MAD；
(3) 将 MAD 框架扩展到对齐labeling任务，展示了标准 MAD 的有效性以及稀疏 MAD 带来的进一步性能改进；
(4) 提供了一些见解来解释 MAD 中稀疏性的有效性；
(5) 将更强大的 LLM 分配给具有更高中心性的智能体，可以在多 LLM 辩论设置中获得更好的整体性能。

如下图，全连接（左下）和邻接连接（右下）通信拓扑之间多智能体辩论系统的准确率（上）和推理输入成本（中）比较。

<p align="center">
<img src="imgs/改进多Agent辩论的稀疏通信拓扑.jpg" width="450" />
</p>